{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0c_TYhQOUe1j"
   },
   "source": [
    "# Ungraded Lab: Introduction to Keras callbacks\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/LuisAngelMendozaVelasco/TensorFlow-Advanced_Techniques_Specialization/blob/master/Custom_Models_Layers_and_Loss_Functions_with_TensorFlow/Week5/Labs/C1_W5_Lab_1_exploring-callbacks.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>\n",
    "\n",
    "In Keras, `Callback` is a Python class meant to be subclassed to provide specific functionality, with a set of methods called at various stages of training (including batch/epoch start and ends), testing, and predicting. Callbacks are useful to get a view on internal states and statistics of the model during training. The methods of the callbacks can  be called at different stages of training/evaluating/inference. Keras has available [callbacks](https://keras.io/api/callbacks/) and we'll show how you can use it in the following sections. Please click the **Open in Colab** badge above to complete this exercise in Colab. This will allow you to take advantage of the free GPU runtime (for faster training) and compatibility with all the packages needed in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uyl69EyRQx-f"
   },
   "source": [
    "## Model methods that take callbacks\n",
    "Users can supply a list of callbacks to the following `tf.keras.Model` methods:\n",
    "* [`fit()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit), [`fit_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit_generator)\n",
    "Trains the model for a fixed number of epochs (iterations over a dataset, or data yielded batch-by-batch by a Python generator).\n",
    "* [`evaluate()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate), [`evaluate_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#evaluate_generator)\n",
    "Evaluates the model for given data or data generator. Outputs the loss and metric values from the evaluation.\n",
    "* [`predict()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict), [`predict_generator()`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#predict_generator)\n",
    "Generates output predictions for the input data or data generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AlT1Kh3uA9lZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 00:25:12.651424: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-23 00:25:12.663767: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-23 00:25:12.667719: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-23 00:25:12.676782: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "# %load_ext tensorboard\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from keras import layers, Sequential, callbacks, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnSljqtsXKfb"
   },
   "source": [
    "# Examples of Keras callback applications\n",
    "The following section will guide you through creating simple [Callback](https://keras.io/api/callbacks/) applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spskRuxvCYQE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ./tensorflow_datasets/horses_or_humans/3.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 00:25:14.437478: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Could not resolve hostname', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8baaa805f84a6ea9b415cc109b91ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7b1a45d0e743a687cd938370985975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3900cd8652d4e8ab28f93b7425165e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faeee792d0ec455883645db4fa175532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b180b5ab4fc43b593abe8afb4317fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling tensorflow_datasets/horses_or_humans/3.0.0.incompleteXFXJZ0/horses_or_humans-train.tfrecord*...:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec40f8fde494f3ca5cd63ba4f35356b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e7452304674b3cad41eba60a4afd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling tensorflow_datasets/horses_or_humans/3.0.0.incompleteXFXJZ0/horses_or_humans-test.tfrecord*...:   0%…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset horses_or_humans downloaded and prepared to ./tensorflow_datasets/horses_or_humans/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 00:25:38.401652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1797 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Download and prepare the horses or humans dataset\n",
    "\n",
    "# Horses_or_humans 3.0.0 has already been downloaded for you\n",
    "path = \"./tensorflow_datasets\"\n",
    "splits, info = tfds.load('horses_or_humans', data_dir=path, as_supervised=True, with_info=True, split=['train[:80%]', 'train[80%:]', 'test'])\n",
    "\n",
    "(train_examples, validation_examples, test_examples) = splits\n",
    "\n",
    "num_examples = info.splits['train'].num_examples\n",
    "num_classes = info.features['label'].num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veIsubKTCZsN"
   },
   "outputs": [],
   "source": [
    "SIZE = 150 #@param {type:\"slider\", min:64, max:300, step:1}\n",
    "IMAGE_SIZE = (SIZE, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "faajLlErCb1S"
   },
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n",
    "    \n",
    "    return  image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVXPuU12Cdka"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lHDkFVaCe48"
   },
   "outputs": [],
   "source": [
    "train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
    "test_batches = test_examples.map(format_image).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxsCqEIkCgUt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 00:25:38.891440: W tensorflow/core/kernels/data/cache_dataset_ops.cc:913] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-08-23 00:25:38.895269: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 150, 150, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_batches.take(1):\n",
    "    pass\n",
    "\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iDBpWvHXCh2A"
   },
   "outputs": [],
   "source": [
    "def build_model(dense_units, input_shape=IMAGE_SIZE + (3,)):\n",
    "    model = Sequential([Input(shape=input_shape),\n",
    "                        layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "                        layers.MaxPooling2D(2, 2),\n",
    "                        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "                        layers.MaxPooling2D(2, 2),\n",
    "                        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "                        layers.MaxPooling2D(2, 2),\n",
    "                        layers.Flatten(),\n",
    "                        layers.Dense(dense_units, activation='relu'),\n",
    "                        layers.Dense(2, activation='softmax')])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ZKGkjagENSw"
   },
   "source": [
    "## [TensorBoard](https://keras.io/api/callbacks/tensorboard/)\n",
    "\n",
    "Enable visualizations for TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeiD2WVEHbex"
   },
   "outputs": [],
   "source": [
    "!rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpLwPLnAEOzv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724394340.732708   67196 service.cc:146] XLA service 0x784674029e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724394340.732744   67196 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2024-08-23 00:25:40.751580: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-23 00:25:40.838129: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "E0000 00:00:1724394342.203403   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394342.338137   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394342.473817   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394342.611047   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394342.749582   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394342.885149   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394343.020378   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-08-23 00:25:43.052144: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{k11=1} for conv (f32[32,16,74,74]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,72,72]{3,2,1,0}, f32[32,16,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "E0000 00:00:1724394343.156814   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394343.292779   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394343.430905   67196 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-08-23 00:25:43.453227: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.401187004s\n",
      "Trying algorithm eng4{k11=1} for conv (f32[32,16,74,74]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,72,72]{3,2,1,0}, f32[32,16,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/26\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6256 - loss: 0.6848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724394345.368435   67196 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6085 - loss: 0.6761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1724394346.977163   67192 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394347.114313   67192 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394347.248150   67192 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1724394347.381079   67192 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - accuracy: 0.6091 - loss: 0.6754 - val_accuracy: 0.4439 - val_loss: 0.7053\n",
      "Epoch 2/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6071 - loss: 0.6474 - val_accuracy: 0.6829 - val_loss: 0.6177\n",
      "Epoch 3/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6891 - loss: 0.6182 - val_accuracy: 0.8195 - val_loss: 0.5638\n",
      "Epoch 4/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7456 - loss: 0.5622 - val_accuracy: 0.4829 - val_loss: 0.8709\n",
      "Epoch 5/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7293 - loss: 0.5320 - val_accuracy: 0.7951 - val_loss: 0.4603\n",
      "Epoch 6/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8200 - loss: 0.4469 - val_accuracy: 0.8927 - val_loss: 0.3741\n",
      "Epoch 7/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8484 - loss: 0.3676 - val_accuracy: 0.8927 - val_loss: 0.3792\n",
      "Epoch 8/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9213 - loss: 0.3174 - val_accuracy: 0.7024 - val_loss: 0.4655\n",
      "Epoch 9/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8658 - loss: 0.3257 - val_accuracy: 0.9561 - val_loss: 0.1908\n",
      "Epoch 10/10\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9442 - loss: 0.2031 - val_accuracy: 0.9561 - val_loss: 0.1704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x784769519d50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "logdir = os.path.join(\"./logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = callbacks.TensorBoard(logdir)\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=10, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJunWOjZE0ir"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv9H4Pc2Mfl7"
   },
   "source": [
    "## [Model Checkpoint](https://keras.io/api/callbacks/model_checkpoint/)\n",
    "\n",
    "Callback to save the Keras model or model weights at some frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PYV4FJ8iMmDq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\n",
      "Epoch 1: saving model to ./weights.01-0.65.keras\n",
      "26/26 - 3s - 111ms/step - accuracy: 0.5560 - loss: 0.6714 - val_accuracy: 0.7366 - val_loss: 0.6479\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 2: saving model to ./weights.02-0.61.keras\n",
      "26/26 - 1s - 20ms/step - accuracy: 0.6582 - loss: 0.6300 - val_accuracy: 0.7268 - val_loss: 0.6077\n",
      "Epoch 3/5\n",
      "\n",
      "Epoch 3: saving model to ./weights.03-0.54.keras\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.7676 - loss: 0.5647 - val_accuracy: 0.6927 - val_loss: 0.5433\n",
      "Epoch 4/5\n",
      "\n",
      "Epoch 4: saving model to ./weights.04-0.60.keras\n",
      "26/26 - 1s - 20ms/step - accuracy: 0.7822 - loss: 0.5047 - val_accuracy: 0.6049 - val_loss: 0.6034\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 5: saving model to ./weights.05-0.67.keras\n",
      "26/26 - 1s - 22ms/step - accuracy: 0.8054 - loss: 0.4547 - val_accuracy: 0.5951 - val_loss: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78480c89b690>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[callbacks.ModelCheckpoint('./weights.{epoch:02d}-{val_loss:.2f}.keras', verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGvjQ8IlMmK6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./saved_model.keras\n",
      "26/26 - 3s - 105ms/step - accuracy: 0.5815 - loss: 0.6632 - val_accuracy: 0.6098 - val_loss: 0.6247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78480c726f90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=1, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[callbacks.ModelCheckpoint('./saved_model.keras', verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1ConwoB0EjD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "Epoch 1: saving model to ./model.keras\n",
      "26/26 - 3s - 111ms/step - accuracy: 0.5900 - loss: 0.6684 - val_accuracy: 0.6585 - val_loss: 0.6350\n",
      "Epoch 2/2\n",
      "\n",
      "Epoch 2: saving model to ./model.keras\n",
      "26/26 - 1s - 21ms/step - accuracy: 0.7080 - loss: 0.6096 - val_accuracy: 0.7512 - val_loss: 0.5719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78480c78c690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=2, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[callbacks.ModelCheckpoint('./model.keras', verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kptNF0--Lznv"
   },
   "source": [
    "## [Early stopping](https://keras.io/api/callbacks/early_stopping/)\n",
    "\n",
    "Stop training when a monitored metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJOJTJYdCkdY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 - 3s - 103ms/step - accuracy: 0.6350 - loss: 0.6589 - val_accuracy: 0.8098 - val_loss: 0.6301\n",
      "Epoch 2/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.7141 - loss: 0.6013 - val_accuracy: 0.7707 - val_loss: 0.5655\n",
      "Epoch 3/50\n",
      "26/26 - 1s - 19ms/step - accuracy: 0.7713 - loss: 0.5359 - val_accuracy: 0.8195 - val_loss: 0.5120\n",
      "Epoch 4/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.8029 - loss: 0.4624 - val_accuracy: 0.8244 - val_loss: 0.4694\n",
      "Epoch 5/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.8102 - loss: 0.4209 - val_accuracy: 0.8976 - val_loss: 0.3832\n",
      "Epoch 6/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.8869 - loss: 0.3369 - val_accuracy: 0.9268 - val_loss: 0.2835\n",
      "Epoch 7/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.9051 - loss: 0.2821 - val_accuracy: 0.9366 - val_loss: 0.2240\n",
      "Epoch 8/50\n",
      "26/26 - 1s - 20ms/step - accuracy: 0.9258 - loss: 0.2345 - val_accuracy: 0.9854 - val_loss: 0.1709\n",
      "Epoch 9/50\n",
      "26/26 - 0s - 18ms/step - accuracy: 0.9465 - loss: 0.1947 - val_accuracy: 0.9220 - val_loss: 0.2024\n",
      "Epoch 10/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.9793 - loss: 0.1364 - val_accuracy: 0.9854 - val_loss: 0.1023\n",
      "Epoch 11/50\n",
      "26/26 - 1s - 19ms/step - accuracy: 0.9647 - loss: 0.1211 - val_accuracy: 0.9902 - val_loss: 0.0990\n",
      "Epoch 12/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.9830 - loss: 0.0982 - val_accuracy: 0.9902 - val_loss: 0.0757\n",
      "Epoch 13/50\n",
      "26/26 - 0s - 19ms/step - accuracy: 0.9805 - loss: 0.0885 - val_accuracy: 0.9902 - val_loss: 0.0646\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78480c452e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=50, \n",
    "          validation_data=validation_batches, \n",
    "          verbose=2,\n",
    "          callbacks=[callbacks.EarlyStopping(patience=3,\n",
    "                                             min_delta=0.05,\n",
    "                                             baseline=0.8,\n",
    "                                             mode='min',\n",
    "                                             monitor='val_loss',\n",
    "                                             restore_best_weights=True,\n",
    "                                             verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mDzWUD4Pqq5"
   },
   "source": [
    "## [CSV Logger](https://keras.io/api/callbacks/csv_logger/)\n",
    "\n",
    "Callback that streams epoch results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cffnMpmGPtMh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.5318 - loss: 0.6802 - val_accuracy: 0.5415 - val_loss: 0.6577\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6431 - loss: 0.6379 - val_accuracy: 0.7317 - val_loss: 0.6009\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7146 - loss: 0.5749 - val_accuracy: 0.8244 - val_loss: 0.5233\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7880 - loss: 0.5143 - val_accuracy: 0.6098 - val_loss: 0.5943\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8162 - loss: 0.4627 - val_accuracy: 0.8195 - val_loss: 0.4501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78480c32b690>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "csv_file = './training.csv'\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[callbacks.CSVLogger(csv_file)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9tkYi03QV7R"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.669105</td>\n",
       "      <td>0.541463</td>\n",
       "      <td>0.657668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.626134</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.600880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.745742</td>\n",
       "      <td>0.559699</td>\n",
       "      <td>0.824390</td>\n",
       "      <td>0.523311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.787105</td>\n",
       "      <td>0.498727</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.594323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.838199</td>\n",
       "      <td>0.442464</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.450118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0      0  0.583942  0.669105      0.541463  0.657668\n",
       "1      1  0.666667  0.626134      0.731707  0.600880\n",
       "2      2  0.745742  0.559699      0.824390  0.523311\n",
       "3      3  0.787105  0.498727      0.609756  0.594323\n",
       "4      4  0.838199  0.442464      0.819512  0.450118"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(csv_file).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dt9C2Y9fRBKN"
   },
   "source": [
    "## [Learning Rate Scheduler](https://keras.io/api/callbacks/learning_rate_scheduler/)\n",
    "\n",
    "Updates the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJi-xY2VRC03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.005.\n",
      "Epoch 1/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.5010 - loss: 0.6815 - val_accuracy: 0.7659 - val_loss: 0.6443 - learning_rate: 0.0050\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0025.\n",
      "Epoch 2/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7404 - loss: 0.6271 - val_accuracy: 0.7561 - val_loss: 0.6259 - learning_rate: 0.0025\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.00125.\n",
      "Epoch 3/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7647 - loss: 0.6115 - val_accuracy: 0.7512 - val_loss: 0.6186 - learning_rate: 0.0012\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000625.\n",
      "Epoch 4/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7863 - loss: 0.5946 - val_accuracy: 0.7659 - val_loss: 0.6086 - learning_rate: 6.2500e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0003125.\n",
      "Epoch 5/5\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7765 - loss: 0.5921 - val_accuracy: 0.7659 - val_loss: 0.6057 - learning_rate: 3.1250e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78476919ead0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "\t\t\t  loss='sparse_categorical_crossentropy',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "  \n",
    "def step_decay(epoch):\n",
    "\tinitial_lr = 0.01\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 1\n",
    "\tlr = initial_lr * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
    "\t\n",
    "\treturn lr\n",
    "\n",
    "model.fit(train_batches, \n",
    "          epochs=5, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[callbacks.LearningRateScheduler(step_decay, verbose=1),\n",
    "\t\t\t\t\t callbacks.TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2S4n8nrbV91"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y0wcuQyJE_UK"
   },
   "source": [
    "## [ReduceLROnPlateau](https://keras.io/api/callbacks/reduce_lr_on_plateau/)\n",
    "\n",
    "Reduce learning rate when a metric has stopped improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4naxZ-eCFB27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.5617 - loss: 0.6685 - val_accuracy: 0.7512 - val_loss: 0.6295 - learning_rate: 0.0100\n",
      "Epoch 2/50\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7047 - loss: 0.6195\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7035 - loss: 0.6191 - val_accuracy: 0.5317 - val_loss: 0.6722 - learning_rate: 0.0100\n",
      "Epoch 3/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7099 - loss: 0.5698 - val_accuracy: 0.7951 - val_loss: 0.5552 - learning_rate: 0.0020\n",
      "Epoch 4/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7699 - loss: 0.5398 - val_accuracy: 0.7756 - val_loss: 0.5406 - learning_rate: 0.0020\n",
      "Epoch 5/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7827 - loss: 0.5249 - val_accuracy: 0.8244 - val_loss: 0.5153 - learning_rate: 0.0020\n",
      "Epoch 6/50\n",
      "\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7773 - loss: 0.5136\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7782 - loss: 0.5128 - val_accuracy: 0.7610 - val_loss: 0.5253 - learning_rate: 0.0020\n",
      "Epoch 7/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8088 - loss: 0.4835 - val_accuracy: 0.7902 - val_loss: 0.4985 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8141 - loss: 0.4799 - val_accuracy: 0.8341 - val_loss: 0.4792 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8261 - loss: 0.4723 - val_accuracy: 0.8049 - val_loss: 0.4789 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8099 - loss: 0.4566 - val_accuracy: 0.8244 - val_loss: 0.4668 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8165 - loss: 0.4558 - val_accuracy: 0.8537 - val_loss: 0.4521 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8271 - loss: 0.4418 - val_accuracy: 0.8049 - val_loss: 0.4662 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8232 - loss: 0.4304 - val_accuracy: 0.8634 - val_loss: 0.4334 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8449 - loss: 0.4379 - val_accuracy: 0.8244 - val_loss: 0.4331 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8398 - loss: 0.4260 - val_accuracy: 0.8927 - val_loss: 0.4131 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8596 - loss: 0.3989 - val_accuracy: 0.8634 - val_loss: 0.4093 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8599 - loss: 0.3914 - val_accuracy: 0.8244 - val_loss: 0.4284 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8538 - loss: 0.4021 - val_accuracy: 0.8488 - val_loss: 0.4006 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8571 - loss: 0.3761 - val_accuracy: 0.8683 - val_loss: 0.3843 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8576 - loss: 0.3869 - val_accuracy: 0.8634 - val_loss: 0.3814 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8538 - loss: 0.3713 - val_accuracy: 0.8683 - val_loss: 0.3684 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8634 - loss: 0.3656 - val_accuracy: 0.9024 - val_loss: 0.3513 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8756 - loss: 0.3470 - val_accuracy: 0.8976 - val_loss: 0.3444 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8736 - loss: 0.3517 - val_accuracy: 0.8732 - val_loss: 0.3539 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8795 - loss: 0.3418 - val_accuracy: 0.8927 - val_loss: 0.3254 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8785 - loss: 0.3405 - val_accuracy: 0.8683 - val_loss: 0.3593 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8898 - loss: 0.3285 - val_accuracy: 0.8976 - val_loss: 0.3151 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8872 - loss: 0.3146 - val_accuracy: 0.8976 - val_loss: 0.3071 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8963 - loss: 0.3010 - val_accuracy: 0.8390 - val_loss: 0.3880 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9157 - loss: 0.2912 - val_accuracy: 0.8927 - val_loss: 0.3050 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8978 - loss: 0.3050 - val_accuracy: 0.9024 - val_loss: 0.3111 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9171 - loss: 0.2779 - val_accuracy: 0.8976 - val_loss: 0.2944 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9017 - loss: 0.2944 - val_accuracy: 0.9171 - val_loss: 0.2678 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9278 - loss: 0.2620 - val_accuracy: 0.9268 - val_loss: 0.2611 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9257 - loss: 0.2590 - val_accuracy: 0.9024 - val_loss: 0.2809 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9354 - loss: 0.2547 - val_accuracy: 0.9171 - val_loss: 0.2487 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9132 - loss: 0.2646 - val_accuracy: 0.9073 - val_loss: 0.2604 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9261 - loss: 0.2505 - val_accuracy: 0.9073 - val_loss: 0.2762 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9282 - loss: 0.2422 - val_accuracy: 0.9073 - val_loss: 0.2637 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9466 - loss: 0.2222 - val_accuracy: 0.9268 - val_loss: 0.2325 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9604 - loss: 0.2180 - val_accuracy: 0.9268 - val_loss: 0.2341 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9422 - loss: 0.2135 - val_accuracy: 0.9122 - val_loss: 0.2559 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9515 - loss: 0.2042 - val_accuracy: 0.9122 - val_loss: 0.2588 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9362 - loss: 0.2162 - val_accuracy: 0.9268 - val_loss: 0.2138 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9463 - loss: 0.2025 - val_accuracy: 0.9366 - val_loss: 0.2112 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9497 - loss: 0.1853 - val_accuracy: 0.9415 - val_loss: 0.1966 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9490 - loss: 0.2001 - val_accuracy: 0.9463 - val_loss: 0.1937 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9604 - loss: 0.1852 - val_accuracy: 0.9366 - val_loss: 0.2017 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9685 - loss: 0.1723 - val_accuracy: 0.9463 - val_loss: 0.1805 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9616 - loss: 0.1736 - val_accuracy: 0.9317 - val_loss: 0.1930 - learning_rate: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x784801e96150>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(dense_units=256)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "model.fit(train_batches, \n",
    "          epochs=50, \n",
    "          validation_data=validation_batches, \n",
    "          callbacks=[callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                 factor=0.2, verbose=1,\n",
    "                                                 patience=1, min_lr=0.001),\n",
    "                     callbacks.TensorBoard(log_dir='./log_dir')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isfTWP4NYudk"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf *.keras *.csv ./log_dir ./logs ./tensorflow_datasets"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExploringCallbacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
