{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Assignment: Implement a Quadratic Layer\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/LuisAngelMendozaVelasco/TensorFlow-Advanced_Techniques_Specialization/blob/master/Custom_Models_Layers_and_Loss_Functions_with_TensorFlow/Week3/Labs/C1W3_Assignment.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's programming exercise, you will build a custom quadratic layer which computes $y = ax^2 + bx + c$. Similar to the ungraded lab, this layer will be plugged into a model that will be trained on the MNIST dataset. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 02:10:26.685864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-22 02:10:26.698166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-22 02:10:26.701972: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-22 02:10:26.709898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import activations, layers, datasets, Sequential, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the quadratic layer (TODO)\n",
    "Implement a simple quadratic layer. It has 3 state variables: $a$, $b$ and $c$. The computation returned is $ax^2 + bx + c$. Make sure it can also accept an activation function.\n",
    "\n",
    "#### `__init__`\n",
    "- call `super(my_fun, self)` to access the base class of `my_fun`, and call the `__init__()` function to initialize that base class.  In this case, `my_fun` is `SimpleQuadratic` and its base class is `Layer`.\n",
    "- self.units: set this using one of the function parameters.\n",
    "- self.activation: The function parameter `activation` will be passed in as a string.  To get the tensorflow object associated with the string, please use `tf.keras.activations.get()` \n",
    "\n",
    "\n",
    "#### `build`\n",
    "The following are suggested steps for writing your code.  If you prefer to use fewer lines to implement it, feel free to do so.  Either way, you'll want to set `self.a`, `self.b` and `self.c`.\n",
    "\n",
    "- a_init: set this to tensorflow's `random_normal_initializer()`\n",
    "- a_init_val: Use the `random_normal_initializer()` that you just created and invoke it, setting the `shape` and `dtype`.\n",
    "    - The `shape` of `a` should have its row dimension equal to the last dimension of `input_shape`, and its column dimension equal to the number of units in the layer.  \n",
    "    - This is because you'll be matrix multiplying x^2 * a, so the dimensions should be compatible.\n",
    "    - set the dtype to 'float32'\n",
    "- self.a: create a tensor using tf.Variable, setting the initial_value and set trainable to True.\n",
    "\n",
    "- b_init, b_init_val, and self.b: these will be set in the same way that you implemented a_init, a_init_val and self.a\n",
    "- c_init: set this to `tf.zeros_initializer`.\n",
    "- c_init_val: Set this by calling the tf.zeros_initializer that you just instantiated, and set the `shape` and `dtype`\n",
    "  - shape: This will be a vector equal to the number of units.  This expects a tuple, and remember that a tuple `(9,)` includes a comma.\n",
    "  - dtype: set to 'float32'.\n",
    "- self.c: create a tensor using tf.Variable, and set the parameters `initial_value` and `trainable`.\n",
    "\n",
    "#### `call`\n",
    "The following section performs the multiplication x^2*a + x*b + c.  The steps are broken down for clarity, but you can also perform this calculation in fewer lines if you prefer.\n",
    "- x_squared: use tf.math.square()\n",
    "- x_squared_times_a: use tf.matmul().  \n",
    "  - If you see an error saying `InvalidArgumentError: Matrix size-incompatible`, please check the order of the matrix multiplication to make sure that the matrix dimensions line up.\n",
    "- x_times_b: use tf.matmul().\n",
    "- x2a_plus_xb_plus_c: add the three terms together.\n",
    "- activated_x2a_plus_xb_plus_c: apply the class's `activation` to the sum of the three terms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "Ga20PttZFXm4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "687a4c4733c3c581631c2b476104b829",
     "grade": false,
     "grade_id": "cell-c302ddc177c098f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "class SimpleQuadratic(layers.Layer):\n",
    "    def __init__(self, units=32, activation=None):\n",
    "        '''Initializes the class and sets up the internal variables'''\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        '''Create the state of the layer (weights)'''\n",
    "\n",
    "        # a and b should be initialized with random normal, c (or the bias) with zeros.\n",
    "        # Remember to set these as trainable.\n",
    "        # YOUR CODE HERE\n",
    "        a_init = tf.random_normal_initializer()\n",
    "        b_init = tf.random_normal_initializer()\n",
    "        c_init = tf.zeros_initializer()\n",
    "        a_init_val = a_init(shape=(input_shape[-1], self.units), dtype=\"float32\")\n",
    "        b_init_val = b_init(shape=(input_shape[-1], self.units), dtype=\"float32\")\n",
    "        c_init_val = c_init(shape=(self.units,), dtype=\"float32\")\n",
    "        self.a = tf.Variable(initial_value=a_init_val, trainable=True)\n",
    "        self.b = tf.Variable(initial_value=b_init_val, trainable=True)\n",
    "        self.c = tf.Variable(initial_value=c_init_val, trainable=True)\n",
    "   \n",
    "    def call(self, inputs):\n",
    "        '''Defines the computation from inputs to outputs'''\n",
    "\n",
    "        # Remember to use self.activation() to get the final output\n",
    "        # YOUR CODE HERE\n",
    "        x_squared = tf.math.square(inputs)\n",
    "        x_squared_times_a = tf.linalg.matmul(x_squared, self.a)\n",
    "        x_times_b = tf.linalg.matmul(inputs, self.b)\n",
    "        x2a_plus_xb_plus_c = x_squared_times_a + x_times_b + self.c\n",
    "        \n",
    "        return self.activation(x2a_plus_xb_plus_c)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.test_simple_quadratic(SimpleQuadratic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now train the model with the `SimpleQuadratic` layer that you just implemented. Please uncomment the cell below to run the training. When you get the expected results, you will need to comment this block again before submitting the notebook to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14tl1CluExjJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 02:10:28.678441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1881 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724314229.851147  304587 service.cc:146] XLA service 0x7b54500076c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724314229.851172  304587 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2024-08-22 02:10:29.861299: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-22 02:10:29.924114: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 213/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.1895 - loss: 2.2448"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724314230.699897  304587 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 707us/step - accuracy: 0.5580 - loss: 1.4473\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7976 - loss: 0.6821\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 704us/step - accuracy: 0.8102 - loss: 0.6157\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.8125 - loss: 0.5970\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8193 - loss: 0.5814\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.5095\n",
      "\n",
      "-----------------------------------------------\n",
      "Loss = 0.4442818760871887\n",
      "Accuracy = 0.8715999722480774\n"
     ]
    }
   ],
   "source": [
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "# THIS CODE SHOULD RUN WITHOUT MODIFICATION\n",
    "# AND SHOULD RETURN TRAINING/TESTING ACCURACY at 97%+\n",
    "\n",
    "mnist = datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = Sequential([Input(shape=(28, 28)),\n",
    "                    layers.Flatten(),\n",
    "                    SimpleQuadratic(128, activation='relu'),\n",
    "                    layers.Dropout(0.2),\n",
    "                    layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"\\n-----------------------------------------------\")\n",
    "print(\"Loss =\", loss)\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**\n",
    "\n",
    "Before submitting, please make sure to follow these steps to avoid getting timeout issues with the grader:\n",
    "\n",
    "1. Make sure to pass all public tests and get an accuracy greater than 97%.\n",
    "2. Click inside the training code cell above.\n",
    "3. Select all lines in this code cell with `Ctrl+A` (Windows/Linux) or `Cmd+A` (Mac), then press `Ctrl+/` (Windows/Linux) or `Cmd+/` (Mac) to comment the entire block. All lines should turn green as before.\n",
    "4. From the menu bar, click `File > Save and Checkpoint`. *This is important*.\n",
    "5. Once saved, click the `Submit Assignment` button."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTFXTWT0EUVuqg6u/LBbJK",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "QuadraticLayer_Answer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
