{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GC7zSrbOWiz0"
   },
   "source": [
    "# Week 4 Assignment: Create a VGG network\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/LuisAngelMendozaVelasco/TensorFlow-Advanced_Techniques_Specialization/blob/master/Custom_Models_Layers_and_Loss_Functions_with_TensorFlow/Week4/Labs/C1W4_Assignment.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will build a class that implements a [VGG network](https://towardsdatascience.com/vgg-neural-networks-the-next-step-after-alexnet-3f91fa9ffe2c) that can be trained to classify images. The model will look something like this:\n",
    "\n",
    "<img src='./images/VGG.png'>\n",
    "\n",
    "It is primarily made up of a series of Conv2D layers followed by a softmax activated layers to classify the image. As you can see, this will be a handful and the code will look huge if you specify each layer individually. As shown in the lectures, you can instead use model subclassing to build complex architectures. You can encapsulate repeating parts of a network then reuse that code when building the final model. You will get to practice that in this exercise. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z01I5nj0NAOu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 03:02:29.141515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-22 03:02:29.153266: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-22 03:02:29.156955: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-22 03:02:29.164644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import Model, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create named-variables dynamically\n",
    "\n",
    "In this assignment, you will see the use of the Python function `vars()`.  This will allow you to use a for loop to define and set multiple variables with a similar name, such as var1, var2, var3.  \n",
    "\n",
    "Please go through the following examples to get familiar with `vars()`, as you will use it when building the VGG model.\n",
    "- You'll start by defining a class `MyClass`\n",
    "- It contains one variable `var1`.  \n",
    "- Create an object of type `MyClass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small class MyClass\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        # One class variable 'a' is set to 1\n",
    "        self.var1 = 1\n",
    "\n",
    "# Create an object of type MyClass()\n",
    "my_obj = MyClass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python classes have an attribute called `__dict__`.\n",
    "- `__dict__` is a Python dictionary that contains the object's instance variables and values as key value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_obj.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call `vars()` and pass in an object, it will call the object's `__dict__` attribute, which is a Python dictionary containing the object's instance variables and their values as ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be familiar with adding new variable like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1, 'var2': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a new instance variable and give it a value\n",
    "my_obj.var2 = 2\n",
    "\n",
    "# Calls vars() again to see the object's instance variables\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another way that you can add an instance variable to an object, using `vars()`.\n",
    "- Retrieve the Python dictionary `__dict__` of the object using vars(my_obj).\n",
    "- Modify this `__dict__` dictionary using square bracket notation and passing in the variable's name as a string: `['var3'] = 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1, 'var2': 2, 'var3': 3}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call vars, passing in the object.  Then access the __dict__ dictionary using square brackets\n",
    "vars(my_obj)['var3'] = 3\n",
    "\n",
    "# Call vars() to see the object's instance variables\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why this is helpful!\n",
    "You may be wondering why you would need another way to access an object's instance variables.  \n",
    "- Notice that when using `vars()`, you can now pass in the name of the variable `var3` as a string.\n",
    "- What if you plan to use several variables that are similarly named (`var4`, `var5` ... `var9`) and wanted a convenient way to access them by incrementing a number?\n",
    "\n",
    "Try this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1,\n",
       " 'var2': 2,\n",
       " 'var3': 3,\n",
       " 'var4': 0,\n",
       " 'var5': 0,\n",
       " 'var6': 0,\n",
       " 'var7': 0,\n",
       " 'var8': 0,\n",
       " 'var9': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a for loop to increment the index 'i'\n",
    "for i in range(4,10):\n",
    "    # Format a string that is var\n",
    "    vars(my_obj)[f'var{i}'] = 0\n",
    "    \n",
    "# View the object's instance variables!\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are couple equivalent ways in Python to format a string.  Here are two of those ways:\n",
    "- f-string: f\"var{i}\"\n",
    "- .format: \"var{}\".format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1\n",
      "var2\n"
     ]
    }
   ],
   "source": [
    "# Format a string using f-string notation\n",
    "i = 1\n",
    "print(f\"var{i}\")\n",
    "\n",
    "# Format a string using .format notation\n",
    "i = 2\n",
    "print(\"var{}\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the variables of a class inside the class definition using `vars(self)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var1': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a small class MyClass\n",
    "class MyClass:\n",
    "    def __init__(self):\n",
    "        # Use vars(self) to access the class's dictionary of variables\n",
    "        vars(self)['var1'] = 1\n",
    "\n",
    "# Create an object of type MyClass()\n",
    "my_obj = MyClass()\n",
    "vars(my_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see this in the upcoming code.  Now you'll start building the VGG network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1T1UMw5YAkp"
   },
   "source": [
    "## Create a generic VGG block (TODO)\n",
    "\n",
    "The VGG Network has blocks of layers, where each block has a varied number of layers.\n",
    "- In order to create blocks of layers that have a customizable number of conv2D layers, you'll define a class `Block`, which can generate a customizable block of layers \n",
    "\n",
    "\n",
    "### `__init__`\n",
    "In the constructor `__init__`, store the conv2D parameters and also define the number of conv2D layers using the parameters passed into `__init__`.\n",
    "- Store the filters, kernel_size, and repetitions as class variables so that they can be used later in the `call` function.\n",
    "- Using a for loop, define a number of Conv2D [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/) layers, based on the number of `repetitions` desired for this block.\n",
    "    - You can define each conv2D layer using `vars` and string formatting to create conv2D_0, conv2D_1, conv2D_3 etc.\n",
    "    - Set these four parameters of Conv2D:\n",
    "        - filters\n",
    "        - kernel_size\n",
    "        - activation: set this to 'relu'\n",
    "        - padding: set this to 'same' (default pading is 'valid').\n",
    "        \n",
    "- Define the [MaxPool2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) layer that follows these Conv2D layers. \n",
    "    - Set the following parameters for MaxPool2D:\n",
    "        - pool_size: this will be a tuple with two values.\n",
    "        - strides: this will also be a tuple with two values.\n",
    "\n",
    "### `call`\n",
    "In `call`, you will connect the layers together.\n",
    "- The 0-th conv2D layer, `conv2D_0`, immediately follows the `inputs`.\n",
    "- For conv2D layers 1,2 and onward, you can use a for loop to connect conv2D_1 to conv2D_0, and connect conv2D_2 to conv2D_1, and so on.\n",
    "- After connecting all of the conv2D_i layers, add connect the max_pool layer and return the max_pool layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "WGJGaxVjM00W",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f19295d8925e1d2e60eefd42a6b4dd8",
     "grade": false,
     "grade_id": "cell-1449db9892707876",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "class Block(Model):\n",
    "    def __init__(self, filters, kernel_size, repetitions, pool_size=2, strides=2):\n",
    "        super(Block, self).__init__()\n",
    "        self.filters = filters # YOUR CODE HERE\n",
    "        self.kernel_size = kernel_size # YOUR CODE HERE\n",
    "        self.repetitions = repetitions # YOUR CODE HERE\n",
    "        \n",
    "        # Define a conv2D_0, conv2D_1, etc based on the number of repetitions\n",
    "        # for i in range(# YOUR CODE HERE):\n",
    "        for i in range(self.repetitions):\n",
    "            \n",
    "            # Define a Conv2D layer, specifying filters, kernel_size, activation and padding.\n",
    "            vars(self)[f'conv2D_{i}'] = layers.Conv2D(filters=self.filters, \n",
    "                                                               kernel_size=self.kernel_size,\n",
    "                                                               activation='relu',\n",
    "                                                               padding='same') # YOUR CODE HERE\n",
    "        \n",
    "        # Define the max pool layer that will be added after the Conv2D blocks\n",
    "        self.max_pool = layers.MaxPool2D(pool_size=pool_size, strides=strides) # YOUR CODE HERE\n",
    "  \n",
    "    def call(self, inputs):\n",
    "        # Access the class's conv2D_0 layer\n",
    "        conv2D_0 = self.conv2D_0 # YOUR CODE HERE\n",
    "        \n",
    "        # Connect the conv2D_0 layer to inputs\n",
    "        x = conv2D_0(inputs) # YOUR CODE HERE\n",
    "\n",
    "        # For the remaining conv2D_i layers from 1 to `repetitions` they will be connected to the previous layer\n",
    "        # for i in range(# YOUR CODE HERE,# YOUR CODE HERE):\n",
    "        for i in range(1, self.repetitions):\n",
    "            # Access conv2D_i by formatting the integer `i`. (hint: check how these were saved using `vars()` earlier)\n",
    "            conv2D_i = vars(self)[f'conv2D_{i}'] # YOUR CODE HERE\n",
    "            \n",
    "            # Use the conv2D_i and connect it to the previous layer\n",
    "            x = conv2D_i(x)\n",
    "\n",
    "        # Finally, add the max_pool layer\n",
    "        max_pool = self.max_pool(x) # YOUR CODE HERE\n",
    "        \n",
    "        return max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4027611c9615b1f518a95d76a81bc8d1",
     "grade": true,
     "grade_id": "cell-2911e521bce8793b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# utils.test_block_class(Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peM2GP6uYT0U"
   },
   "source": [
    "## Create the Custom VGG network (TODO)\n",
    "This model stack has a series of VGG blocks, which can be created using the `Block` class that you defined earlier.\n",
    "\n",
    "### `__init__`\n",
    "- Recall that the `__init__` constructor of `Block` takes several function parameters, \n",
    "    - filters, kernel_size, repetitions: you'll set these.\n",
    "    - kernel_size and strides: you can use the default values.\n",
    "- For blocks a through e, build the blocks according to the following specifications:\n",
    "- block_a: 64  filters, kernel_size 3, repetitions 2\n",
    "- block_b: 128 filters, kernel_size 3, repetitions 2\n",
    "- block_c: 256 filters, kernel_size 3, repetitions 3\n",
    "- block_d: 512 filters, kernel_size 3, repetitions 3\n",
    "- block_e: 512 filters, kernel_size 3, repetitions 3\n",
    "\n",
    "After block 'e', add the following layers:\n",
    "- flatten: use [Flatten](https://keras.io/api/layers/reshaping_layers/flatten/).\n",
    "- fc: create a fully connected layer using [Dense](https://keras.io/api/layers/core_layers/dense/).  Give this 256 units, and a `'relu'` activation.\n",
    "- classifier: create the classifier using a Dense layer.  The number of units equals the number of classes.  For multi-class classification, use a `'softmax'` activation.\n",
    "\n",
    "### `call`\n",
    "Connect these layers together using the functional API syntax:\n",
    "- inputs\n",
    "- block_a\n",
    "- block_b\n",
    "- block_c\n",
    "- block_d\n",
    "- block_e\n",
    "- flatten\n",
    "- fc\n",
    "- classifier\n",
    "\n",
    "Return the classifier layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "yD-paeGiNGvz",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "523346a38f53bc31e080114e98e8eca6",
     "grade": false,
     "grade_id": "cell-d9e90af0898eb47f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please uncomment all lines in this cell and replace those marked with `# YOUR CODE HERE`.\n",
    "# You can select all lines in this code cell with Ctrl+A (Windows/Linux) or Cmd+A (Mac), then press Ctrl+/ (Windows/Linux) or Cmd+/ (Mac) to uncomment.\n",
    "\n",
    "class MyVGG(Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MyVGG, self).__init__()\n",
    "\n",
    "        # Creating blocks of VGG with the following \n",
    "        # (filters, kernel_size, repetitions) configurations\n",
    "        self.block_a = Block(filters=64, kernel_size=3, repetitions=2) # YOUR CODE HERE #\n",
    "        self.block_b = Block(filters=128, kernel_size=3, repetitions=2) # YOUR CODE HERE #\n",
    "        self.block_c = Block(filters=256, kernel_size=3, repetitions=3) # YOUR CODE HERE #\n",
    "        self.block_d = Block(filters=512, kernel_size=3, repetitions=3) # YOUR CODE HERE #\n",
    "        self.block_e = Block(filters=512, kernel_size=3, repetitions=3) # YOUR CODE HERE #\n",
    "\n",
    "        # Classification head\n",
    "        # Define a Flatten layer\n",
    "        self.flatten = layers.Flatten() # YOUR CODE HERE\n",
    "        # Create a Dense layer with 256 units and ReLU as the activation function\n",
    "        self.fc = layers.Dense(256, activation='relu') # YOUR CODE HERE\n",
    "        # Finally add the softmax classifier using a Dense layer\n",
    "        self.classifier = layers.Dense(num_classes, activation='softmax') # YOUR CODE HERE\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Chain all the layers one after the other\n",
    "        x = self.block_a(inputs) # YOUR CODE HERE\n",
    "        x = self.block_b(x) # YOUR CODE HERE\n",
    "        x = self.block_c(x) # YOUR CODE HERE\n",
    "        x = self.block_d(x) # YOUR CODE HERE\n",
    "        x = self.block_e(x) # YOUR CODE HERE\n",
    "        x = self.flatten(x) # YOUR CODE HERE\n",
    "        x = self.fc(x) # YOUR CODE HERE\n",
    "        x = self.classifier(x) # YOUR CODE HERE\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c72733dcd5baccf2728b5b2460caf515",
     "grade": true,
     "grade_id": "cell-559ac19437f4f2b2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# utils.test_myvgg_class(MyVGG, Block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and train the VGG network (Optional)\n",
    "\n",
    "If you passed all tests above, then you've successfully built the model for your image classifier. Congratulations! You can submit your work now before proceeding. \n",
    "\n",
    "The next steps in the pipeline will be loading the dataset and training your VGG network. The code is shown below but it is only for reference and is **not required to complete the assignment**. Please do not uncomment it because it will cause a grader timeout because of the slow training time. The grader environment does not have an accelerator enabled.\n",
    "\n",
    "If you want to train with your VGG network, one way is to download your notebook (`File -> Download As -> Notebook`), then upload to [Colab](https://colab.research.google.com). From there, you can use a GPU runtime (`Runtime -> Change Runtime type`) prior to running the cells. Just make sure **to comment out the imports and calls to `utils.py`** so you don't get `File Not Found` errors. Again, this part is only for reference and is not required for grading. For this lab, we will only grade how you built your model using subclassing. You will get to training and evaluating your models in the next courses of this Specialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MaF763OKNJxU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 03:02:31.284088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1971 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724317352.938613  313925 service.cc:146] XLA service 0x7b162400cca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724317352.938718  313925 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2024-08-22 03:02:32.967257: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-22 03:02:33.129306: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-08-22 03:02:33.734493: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 939.37MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:33.734525: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:33.836402: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.74GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:34.785553: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:35.186113: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 800.43MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:36.151588: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:37.592802: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:38.073551: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 898.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:39.841087: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-08-22 03:02:41.004932: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1724317370.155166  313925 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m223/727\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 248ms/step - accuracy: 0.5032 - loss: 0.6945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m259/727\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 247ms/step - accuracy: 0.5044 - loss: 0.6943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: unknown JFIF revision number 0.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m271/727\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 247ms/step - accuracy: 0.5049 - loss: 0.6943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 396 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m315/727\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:41\u001b[0m 247ms/step - accuracy: 0.5063 - loss: 0.6940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/727\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 247ms/step - accuracy: 0.5078 - loss: 0.6937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 252 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m365/727\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:29\u001b[0m 247ms/step - accuracy: 0.5079 - loss: 0.6937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m380/727\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:25\u001b[0m 247ms/step - accuracy: 0.5084 - loss: 0.6936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m540/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 246ms/step - accuracy: 0.5158 - loss: 0.6927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m642/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m20s\u001b[0m 246ms/step - accuracy: 0.5207 - loss: 0.6920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 2226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m659/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m16s\u001b[0m 246ms/step - accuracy: 0.5215 - loss: 0.6919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m673/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m13s\u001b[0m 246ms/step - accuracy: 0.5222 - loss: 0.6918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m709/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m4s\u001b[0m 245ms/step - accuracy: 0.5238 - loss: 0.6915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m718/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 245ms/step - accuracy: 0.5242 - loss: 0.6915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 228 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m727/727\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 268ms/step - accuracy: 0.5247 - loss: 0.6914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7b17189e0b10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reference only. Please do not uncomment in Coursera Labs because it might cause the grader to time out.\n",
    "# You can upload your notebook to Colab instead if you want to try the code below.\n",
    "\n",
    "# Download the dataset\n",
    "dataset = tfds.load('cats_vs_dogs', split=tfds.Split.TRAIN, data_dir='./data')\n",
    "\n",
    "# Initialize VGG with the number of classes \n",
    "vgg = MyVGG(num_classes=2)\n",
    "\n",
    "# Compile with losses and metrics\n",
    "vgg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(features):\n",
    "    # Resize and normalize\n",
    "    image = tf.image.resize(features['image'], (224, 224))\n",
    "\n",
    "    return tf.cast(image, tf.float32) / 255., features['label']\n",
    "\n",
    "# Apply transformations to dataset\n",
    "dataset = dataset.map(preprocess).batch(32)\n",
    "\n",
    "# Train the custom VGG model\n",
    "vgg.fit(dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ExerciseAnswer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
